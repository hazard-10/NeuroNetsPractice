{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_set = {}\n",
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in words:\n",
    "    characters = ['.']+list(w)+['.']\n",
    "    for char1, char2 in zip(characters, characters[1:]):\n",
    "        b_index = (char1, char2)\n",
    "        bigram_set[b_index] = bigram_set.get(b_index, 0)+1\n",
    "bigram_set\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.zeros((27, 27), dtype=torch.int32)\n",
    "all_single_chars = sorted(list(set(''.join(words))))\n",
    "char_to_index = {s:i+1 for i,s in enumerate(all_single_chars)}\n",
    "char_to_index['.'] = 0\n",
    "index_to_char = {i:s for s,i in char_to_index.items()}; index_to_char\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in words:\n",
    "    characters = ['.']+list(w)+['.']\n",
    "    for char1, char2 in zip(characters, characters[1:]):\n",
    "        indx_1 = char_to_index[char1]\n",
    "        indx_2 = char_to_index[char2]\n",
    "        N[indx_1, indx_2]+=1\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.imshow(N, cmap=\"Blues\")\n",
    "for i in range(27):\n",
    "    for j in range(27):\n",
    "        display_char = index_to_char[i]+index_to_char[j]\n",
    "        plt.text(j, i ,display_char, ha=\"center\", va=\"bottom\", color=\"gray\")\n",
    "        plt.text(j, i, N[i, j].item(),  ha=\"center\", va=\"top\", color=\"gray\")\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_of_N = N[0].float()\n",
    "p_of_N = p_of_N / p_of_N.sum(); p_of_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6064, 0.3033, 0.0903])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "p = torch.rand(3, generator=g) ; p = p / p.sum()\n",
    "p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 2, 0, 0, 2, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 2, 0, 0,\n",
       "        1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "        0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 1, 0,\n",
       "        0, 1, 1, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.multinomial(p, num_samples=100, replacement=True, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = N.float()\n",
    "# P = P/ P.sum(1, keepdim=True)\n",
    "P /= P.sum(1, keepdim=True) \n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "for i in range(10):\n",
    "    indx = 0\n",
    "    cur_name = \"\"\n",
    "    while True:\n",
    "        # p = N[indx].float()\n",
    "        # p = p / p.sum()\n",
    "        p = P[indx]\n",
    "        indx = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        cur_name+= index_to_char[indx]\n",
    "        if indx == 0: break\n",
    "    print(cur_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create the training set for all bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  5, 13, 13,  1]), tensor([ 5, 13, 13,  1,  0]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_tensor, y_tensor = [], []\n",
    "\n",
    "for w in words[:1]:\n",
    "    characters = ['.']+list(w)+['.']\n",
    "    for char1, char2 in zip(characters, characters[1:]):\n",
    "        indx_1 = char_to_index[char1]\n",
    "        indx_2 = char_to_index[char2]\n",
    "        x_tensor.append(indx_1)\n",
    "        y_tensor.append(indx_2)\n",
    "\n",
    "inputs = torch.tensor(x_tensor  )\n",
    "labels = torch.tensor(y_tensor)\n",
    "inputs, labels       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2881, 4.5867, 1.7456, 1.9147, 3.4133, 1.7690, 0.0894, 0.6723, 0.3196,\n",
       "         0.3732, 5.7343, 0.2648, 0.4554, 1.2624, 0.5854, 0.8660, 0.9247, 7.4040,\n",
       "         2.7512, 0.6131, 1.7173, 1.4257, 0.2730, 1.6587, 3.2454, 0.9583, 2.8068],\n",
       "        [1.1050, 0.8517, 3.2948, 0.6502, 4.8913, 4.8815, 2.3345, 0.6285, 0.5486,\n",
       "         0.2825, 0.5729, 0.7040, 1.0087, 1.5162, 0.5349, 2.5622, 0.4564, 2.9916,\n",
       "         0.5973, 0.9385, 5.4576, 3.1681, 0.5101, 0.8404, 1.6139, 0.5408, 0.3278],\n",
       "        [1.3293, 0.3635, 2.0222, 0.3700, 1.7566, 0.7293, 1.0571, 5.1339, 9.5884,\n",
       "         0.5652, 5.5594, 1.8958, 1.0199, 2.1193, 0.0503, 0.7690, 3.6789, 0.6606,\n",
       "         0.1719, 0.6703, 3.1813, 1.7148, 2.6905, 1.0157, 0.9759, 0.2621, 0.0760],\n",
       "        [1.3293, 0.3635, 2.0222, 0.3700, 1.7566, 0.7293, 1.0571, 5.1339, 9.5884,\n",
       "         0.5652, 5.5594, 1.8958, 1.0199, 2.1193, 0.0503, 0.7690, 3.6789, 0.6606,\n",
       "         0.1719, 0.6703, 3.1813, 1.7148, 2.6905, 1.0157, 0.9759, 0.2621, 0.0760],\n",
       "        [2.9409, 8.5500, 4.1230, 2.0707, 2.3103, 0.9816, 2.3873, 4.1242, 0.5366,\n",
       "         0.8426, 0.1937, 4.8065, 7.6258, 0.3933, 2.7748, 0.7439, 0.4645, 1.9338,\n",
       "         0.5469, 0.4206, 0.5594, 4.1469, 2.3803, 0.9441, 1.5400, 4.4357, 1.8817]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_encoded = F.one_hot(inputs, num_classes = 27).float()\n",
    "weights = torch.randn((27,27)) # random from normal distribution\n",
    "\n",
    "log_counts = input_encoded @ weights\n",
    "log_counts # interpretated as log count, the count add as the distribution of different characeters.\n",
    "counts = log_counts.exp() # count distribution\n",
    "prob = counts / counts.sum(1, keepdims =True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
